type: Text2color
model:
    # hyperparameter of model
    arch: GPT2LMHeadModel
    name: skt/kogpt2-base-v2
    config:
        n_ctx: 1024,
        n_embd: 768,
        n_head: 4,
        n_inner: null,
        n_layer: 4,
        n_positions: 1024,
        pad_token_id: 3,

data:
    dataset: Text2ColorDataset
    train_path: /home/guest/gihwan/AI_software/dataset/train/scene.all.xlsx
    valid_path: /home/guest/gihwan/AI_software/dataset/valid/scene.all.xlsx
    tokenizer: PreTrainedTokenizerFast
    tokenizer_name: skt/kogpt2-base-v2
    tokenizer_configs:
        bos_token: '</s>'
        eos_token: '</s>'
        unk_token: '<unk>'
        pad_token: '<pad>'
        mask_token: '<mask>'
testing:
    is_test: True

training:
    gpu: 0
    n_workers: 1
    epoch: 20000
    batch_size: 4
    val_interval: 500
    print_interval: 25
    loss:
        name: CrossEntropyLoss
        thresh: 0.7
        ignore_index: 250
    optimizer:
        name: adamw
        lr: 1.0e-6
        weight_decay: 5.0e-4


    resume:
    visdom: False

validating:
    densecrf: False
    resume: /home/guest/gihwan/AI_software/term/runs/onlyinput_GPT2LMHeadModel_Text2ColorDataset_55.pkl
    n_workers: 1
    batch_size: 1